{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for scraping RT\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Imports for scraping individual websites\n",
    "import requests\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Imports for data formatting\n",
    "import uuid\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAY = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def generate_json(author, text, summary, date_created, source_url):\n",
    "    \"\"\"\n",
    "    Generate a JSON representation of a document with author and content information.\n",
    "\n",
    "    Parameters:\n",
    "    author (str): The name or identifier of the document's author.\n",
    "    text (str): The full text content of the document.\n",
    "    summary (str): A summary or brief description of the document.\n",
    "    date_created (str): The date the document was created (formatted as \"%Y %m, %d\").\n",
    "    source_url (str): The source url of the document\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary representing the document in JSON format with various attributes.\n",
    "    \"\"\"\n",
    "    output = {}\n",
    "    # get doc id\n",
    "    m = hashlib.md5()\n",
    "    m.update(text.encode('utf-8'))\n",
    "    output['documentID'] = str(uuid.UUID(m.hexdigest())) \n",
    "\n",
    "    # get authorID\n",
    "    m = hashlib.md5()\n",
    "    m.update(author.encode('utf-8'))\n",
    "    output['authorIDs'] = [str(uuid.UUID(m.hexdigest()))]\n",
    "\n",
    "    output['fullText'] = text\n",
    "    output[\"spanAttribution\"] = [{\"authorID\":output['authorIDs'][0],\n",
    "                                    \"start\":0,\n",
    "                                    \"end\":len(text)}]\n",
    "    output[\"isNeedle\"] = False\n",
    "    output[\"collectionNum\"] = \"HRS 1\"\n",
    "    output[\"source\"] = source_url\n",
    "    output[\"dateCollected\"] = TODAY\n",
    "    output[\"dateCreated\"] = date_created\n",
    "    # output[\"dateCreated\"] = datetime.datetime.strptime(date_created, \"%b %d, %Y\").strftime(\"%Y-%m-%d\")\n",
    "    output[\"publiclyAvailable\"] = True\n",
    "    output[\"deidentified\"] = True\n",
    "    output[\"languages\"] = [\"en\"]\n",
    "    output[\"lengthWords\"] = len(text.split(' '))\n",
    "    output[\"sourceSpecific\"] = {\n",
    "        \"authorName\": author,\n",
    "        \"rtSummary\": summary,\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):\n",
    "    \"\"\"\n",
    "    Scrapes and process text from a webpage, focusing on <p> tags.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL of the webpage to scrape.\n",
    "\n",
    "    Returns:\n",
    "    str: The cleaned-up text extracted from the web page, or an empty string if an issue occurs during scraping.\n",
    "    \"\"\"\n",
    "\n",
    "    # returns class attributes of an HTML element or \"NOCLASS\" if it doesn't have any.\n",
    "    def get_class(p):\n",
    "        return ''.join(p['class']) if p.has_attr('class') else \"&&NOCLASS&&\"\n",
    "\n",
    "    p_dict = defaultdict(list)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # if we've been redirected, return.\n",
    "        if response.url != url:\n",
    "            return \"\"\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # finds all <p> tags\n",
    "        paragraphs = soup.find_all('p')\n",
    "\n",
    "        for p in paragraphs:\n",
    "            if len(p.text.split(' ')) > 5:\n",
    "                p_dict[get_class(p)].append(p.text)\n",
    "\n",
    "    except Exception as e:\n",
    "        return \"\"\n",
    "\n",
    "    # Find the class with the longest list of paragraphs\n",
    "    longest_key = max(p_dict, key=lambda k: len(p_dict[k]))\n",
    "\n",
    "    # Combine and clean text\n",
    "    full_text = re.sub(r'\\s+', ' ', ' '.join(p_dict[longest_key])).strip()\n",
    "\n",
    "    return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews(critic): \n",
    "    driver = webdriver.Chrome()\n",
    "    page_url = f'https://www.rottentomatoes.com/critics/{critic}/movies/'\n",
    "    driver.get(page_url)\n",
    "    reviews = []\n",
    "    next_wait = WebDriverWait(driver, 3)\n",
    "    table_wait = WebDriverWait(driver, 7.5) \n",
    "    while True:\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        table = soup.find('table', {'data-qa': 'critic-reviews-table'})\n",
    "        if table:\n",
    "            rows = table.find('tbody').find_all('tr', {'data-qa': 'row'})\n",
    "            for row in rows:\n",
    "                review_td = row.find('td', {'data-qa': 'critic-review'})\n",
    "                if review_td:\n",
    "                    date_created = datetime.strptime(review_td.find('div').find('span').text, \"%b %d, %Y\")\n",
    "                    if date_created < datetime(2021, 1, 1):\n",
    "                        rt_summary = review_td.find('span').text.strip()\n",
    "                        review_url = review_td.find('a', string=\"Read More\")['href']\n",
    "                        if len(review_url) > 0:\n",
    "                            fullText = scrape_page(review_url)\n",
    "                            reviews.append(generate_json(\n",
    "                                critic,\n",
    "                                fullText,\n",
    "                                rt_summary,\n",
    "                                date_created.strftime(\"%Y-%m-%d\"),\n",
    "                                review_url\n",
    "                            ))\n",
    "        try:\n",
    "            next_button = next_wait.until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, 'rt-button.next'))\n",
    "            )\n",
    "            next_button.click()\n",
    "\n",
    "            try:\n",
    "                table_wait.until(EC.staleness_of(driver.find_element(By.CSS_SELECTOR, 'table[data-qa=\"critic-reviews-table\"]')))\n",
    "            except TimeoutException:\n",
    "                print(\"TDS timeout. Critic \" + critic + \" scraping terminated with \" + str(len(reviews)) + \" reviews.\")\n",
    "                driver.quit()\n",
    "                return reviews\n",
    "            time.sleep(0.15)\n",
    "        except Exception as e:\n",
    "            break\n",
    "        \n",
    "    driver.quit()\n",
    "    print(\"reviews found for critic \" + critic + \": \" + str(len(reviews)))\n",
    "    return reviews\n",
    "\n",
    "\n",
    "def get_reviews(critics):\n",
    "    review_list = []\n",
    "    for critic in critics:\n",
    "        review_list.append(scrape_reviews(critic))\n",
    "    return review_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m critics \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39malonso-duralde\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdavid-sims\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mjami-bernard\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39med-gonzalez\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnell-minow\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msara-michelle-fetters-8689\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvalerie-complex\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvictoria-luxford\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwenlei-ma\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m scraped \u001b[39m=\u001b[39m get_reviews(critics)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mrtlinks.jsonl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m link_jsonl, \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcritics.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m critic_list:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m rd \u001b[39min\u001b[39;00m scraped: \n",
      "\u001b[1;32m/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m review_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mfor\u001b[39;00m critic \u001b[39min\u001b[39;00m critics:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     review_list\u001b[39m.\u001b[39mappend(scrape_reviews(critic))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mreturn\u001b[39;00m review_list\n",
      "\u001b[1;32m/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39mChrome()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m page_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://www.rottentomatoes.com/critics/\u001b[39m\u001b[39m{\u001b[39;00mcritic\u001b[39m}\u001b[39;00m\u001b[39m/movies/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m driver\u001b[39m.\u001b[39;49mget(page_url)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reviews \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaeljiang/Desktop/BBL/sadiri/rt_scraping/main.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m next_wait \u001b[39m=\u001b[39m WebDriverWait(driver, \u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:353\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m: url})\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:342\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m    340\u001b[0m         params[\u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[0;32m--> 342\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m    344\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:294\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    292\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[1;32m    293\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 294\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:315\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    312\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 315\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    316\u001b[0m     statuscode \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus\n\u001b[1;32m    317\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_body(\n\u001b[1;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1379\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "critics = [\"alonso-duralde\", \"david-sims\", \"jami-bernard\", \"ed-gonzalez\", \"nell-minow\", \"sara-michelle-fetters-8689\", \"valerie-complex\", \"victoria-luxford\", \"wenlei-ma\"]\n",
    "scraped = get_reviews(critics)\n",
    "with open(\"rtlinks.jsonl\", 'a') as link_jsonl, open(\"critics.txt\", 'a') as critic_list:\n",
    "    for rd in scraped: \n",
    "        critic = rd[\"critic\"]\n",
    "        critic_list.write(critic + ': ' + str(rd[\"review_count\"]) + '\\n')\n",
    "        link_jsonl.write(json.dumps(rd) + '\\n')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
