{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset\n",
    "\n",
    "This notebook generaates dataset from a integrated `.jsonl` file to the datasets\n",
    "\n",
    "\n",
    "### Steps\n",
    "1. Partition\n",
    "2. Align\n",
    "3. Merge\n",
    "4. Convert to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from partition import partition\n",
    "from align import align\n",
    "from merge import merge_datasets\n",
    "from convert_to_datasets import create_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(path: str):\n",
    "    \"\"\"Creates path if not exists.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Created the path: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the path: /shared/3/projects/hiatus/rotten_tomatoes/generated_data/rtcorpus\n",
      "Input file path: /shared/3/projects/hiatus/rotten_tomatoes/raw_data/rtcorpus.jsonl\n",
      "Output file path: /shared/3/projects/hiatus/rotten_tomatoes/generated_data/rtcorpus\n"
     ]
    }
   ],
   "source": [
    "input_base_path = '/shared/3/projects/hiatus/rotten_tomatoes'\n",
    "# hrs_release_08 = [\n",
    "#     'hrs1_08-14-23_background_bgg_350_anonymized.jsonl',\n",
    "#     'hrs1_08-14-23_background_globalvoices_anonymized.jsonl',\n",
    "#     'hrs1_08-14-23_background_instructables_anonymized.jsonl',\n",
    "#     'hrs1_08-14-23_background_stackexchange_literature_anonymized.jsonl',\n",
    "#     'hrs1_08-14-23_background_stackexchange_stem_anonymized.jsonl',\n",
    "#     'hrs1_08-14-23_boardgamegeek_foreground_anonymized.jsonl',\n",
    "#     'hrs1_08-14-23_globalvoices_foreground_anonymized.jsonl',\n",
    "#     'hrs1_08-14-23_instructables_foreground_anonymized.jsonl',\n",
    "#     'hrs1_08-14-23_stackexchangehumanities_foreground_anonymized.jsonl',\n",
    "#     'hrs1_08-14-23_stackexchangestem_foreground_anonymized.jsonl']\n",
    "# hrs_release_08_names = [\n",
    "#     'background_bgg_350',\n",
    "#     'background_globalvoices',\n",
    "#     'background_instructables',\n",
    "#     'background_stackexchange_literature',\n",
    "#     'background_stackexchange_stem',\n",
    "#     'boardgamegeek_foreground',\n",
    "#     'globalvoices_foreground',\n",
    "#     'instructables_foreground',\n",
    "#     'stackexchangehumanities_foreground',\n",
    "#     'stackexchangestem_foreground'\n",
    "# ]\n",
    "\n",
    "hrs_file = \"rtcorpus.jsonl\"\n",
    "output_name = \"rtcorpus\"\n",
    "\n",
    "### Set dirs.\n",
    "input_file = os.path.join(input_base_path,'raw_data', hrs_file)\n",
    "output_path = os.path.join(input_base_path, 'generated_data', output_name)\n",
    "create_path(output_path)\n",
    "print(\"Input file path:\", input_file)\n",
    "print(\"Output file path:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Partition\n",
    "\n",
    "Generate the queries and candidates from the source data .jsonl file\n",
    "\n",
    "```\n",
    "Input: 'hrs1_08-14-23_background_bgg_350_anonymized.jsonl'\n",
    "Output: \n",
    "        `dev_candidates.jsonl`\n",
    "        `test_candidates.jsonl`\n",
    "        `train_candidates.jsonl`\n",
    "        `dev_queries.jsonl`\n",
    "        `test_queries.jsonl`\n",
    "        `train_queries.jsonl`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading meta data...\n",
      "INFO:root:40 dev samples\n",
      "INFO:root:80 test samples\n",
      "INFO:root:678 training samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling text pairs...\n",
      "saving text pair samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25175it [00:00, 25812.67it/s]\n",
      "25175it [00:00, 33540.05it/s]\n",
      "25175it [00:00, 33448.23it/s]\n"
     ]
    }
   ],
   "source": [
    "nrows = None  # None to use the whole file\n",
    "partition(input_file, output_path, nrows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2: Align\n",
    "\n",
    "Align the authors in the candidate and query files and assert that are no overlapping documents in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning dev dataset!\n",
      "Aligning test dataset!\n",
      "Aligning train dataset!\n"
     ]
    }
   ],
   "source": [
    "print(\"Aligning dev dataset!\")\n",
    "align(os.path.join(output_path, 'dev_candidates.jsonl'), os.path.join(output_path, 'dev_queries.jsonl'))\n",
    "\n",
    "print(\"Aligning test dataset!\")\n",
    "align(os.path.join(output_path, 'test_candidates.jsonl'), os.path.join(output_path, 'test_queries.jsonl'))\n",
    "\n",
    "print(\"Aligning train dataset!\")\n",
    "align(os.path.join(output_path, 'train_candidates.jsonl'), os.path.join(output_path, 'train_queries.jsonl'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3: Merge\n",
    "\n",
    "Merge the candidates and queries into a single file for each split. E.g. `train.jsonl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging train data\n",
      "/shared/3/projects/hiatus/rotten_tomatoes/generated_data/rtcorpus/train_queries.jsonl\n",
      "/shared/3/projects/hiatus/rotten_tomatoes/generated_data/rtcorpus/train_candidates.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "678it [00:00, 3818.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dev data\n",
      "/shared/3/projects/hiatus/rotten_tomatoes/generated_data/rtcorpus/dev_queries.jsonl\n",
      "/shared/3/projects/hiatus/rotten_tomatoes/generated_data/rtcorpus/dev_candidates.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:00, 3421.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging test data\n",
      "/shared/3/projects/hiatus/rotten_tomatoes/generated_data/rtcorpus/test_queries.jsonl\n",
      "/shared/3/projects/hiatus/rotten_tomatoes/generated_data/rtcorpus/test_candidates.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:00, 3898.82it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging train data\")\n",
    "train_input_paths = [(os.path.join(p, 'train_queries.jsonl'), os.path.join(p, 'train_candidates.jsonl')) for p in [output_path]]\n",
    "merge_datasets(train_input_paths, os.path.join(output_path, 'train.jsonl'))\n",
    "\n",
    "print(\"Merging dev data\")\n",
    "dev_input_paths = [(os.path.join(output_path, 'dev_queries.jsonl'), os.path.join(output_path, 'dev_candidates.jsonl')) for p in [output_path]]\n",
    "merge_datasets(dev_input_paths, os.path.join(output_path, 'dev.jsonl'))\n",
    "\n",
    "print(\"Merging test data\")\n",
    "test_input_paths = [(os.path.join(output_path, 'test_queries.jsonl'), os.path.join(output_path, 'test_candidates.jsonl')) for p in [output_path]]\n",
    "merge_datasets(test_input_paths, os.path.join(output_path, 'test.jsonl'))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4: Convert To Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0274dad110473eb2ddd2dfdc624007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20884244b734de5a0628666f0479226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6e3b5e7fb34f19afe0fdbef7ed37a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c5015f9d994587aafd41b3935fc974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dev dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d585dda1378d4b27a75700c31b3a2e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7a5cea4f7d43dc8cea40d92d11002b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75815de347364e7a97f001f0bdbefa78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588d7aab614b4223900731a49932de7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6799be8acf4ff0a2ec595840e100f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e819804a9c8a49fbbb29887478312809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c44fa58b686401c9aba2400a7e31955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5426763c594d4292bec67015e3ebae69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Creating training dataset...')\n",
    "train_inpath = os.path.join(output_path, 'train.jsonl')\n",
    "train_outpath = os.path.join(output_path, 'train')\n",
    "create_dataset(train_inpath, train_outpath)\n",
    "\n",
    "print('Creating dev dataset...')\n",
    "dev_inpath = os.path.join(output_path, 'dev.jsonl')\n",
    "dev_outpath = os.path.join(output_path, 'dev')\n",
    "create_dataset(dev_inpath, dev_outpath)\n",
    "\n",
    "print('Creating test dataset...')\n",
    "test_inpath = os.path.join(output_path, 'test.jsonl')\n",
    "test_outpath = os.path.join(output_path, 'test')\n",
    "create_dataset(test_inpath, test_outpath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
